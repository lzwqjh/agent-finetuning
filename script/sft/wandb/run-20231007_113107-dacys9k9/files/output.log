

  0%|                                                                                                                                                                       | 1/2550 [00:10<7:04:00,  9.98s/it]


































































































  4%|██████▍                                                                                                                                                              | 100/2550 [05:24<2:09:19,  3.17s/it][INFO|trainer.py:3081] 2023-10-07 11:36:45,085 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-10-07 11:36:45,085 >>   Num examples = 825
[INFO|trainer.py:3086] 2023-10-07 11:36:45,085 >>   Batch size = 1
{'loss': 5.1632, 'learning_rate': 9.99854361016621e-05, 'epoch': 0.04}












 92%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████             | 191/207 [00:23<00:01,  8.34it/s]



































































































  8%|████████████▉                                                                                                                                                        | 200/2550 [10:53<1:57:36,  3.00s/it][INFO|trainer.py:3081] 2023-10-07 11:42:14,183 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-10-07 11:42:14,184 >>   Num examples = 825
[INFO|trainer.py:3086] 2023-10-07 11:42:14,184 >>   Batch size = 1
{'loss': 0.8715, 'learning_rate': 9.942975930847631e-05, 'epoch': 0.08}












 93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊            | 192/207 [00:23<00:01,  8.47it/s]



































































































 12%|███████████████████▍                                                                                                                                                 | 300/2550 [16:16<1:43:00,  2.75s/it][INFO|trainer.py:3081] 2023-10-07 11:47:36,748 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-10-07 11:47:36,748 >>   Num examples = 825
[INFO|trainer.py:3086] 2023-10-07 11:47:36,748 >>   Batch size = 1
{'loss': 0.5939, 'learning_rate': 9.807745395267324e-05, 'epoch': 0.12}













 97%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏    | 201/207 [00:25<00:00,  8.28it/s]



































































































 16%|█████████████████████████▉                                                                                                                                           | 400/2550 [21:17<1:38:10,  2.74s/it][INFO|trainer.py:3081] 2023-10-07 11:52:37,905 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-10-07 11:52:37,905 >>   Num examples = 825
[INFO|trainer.py:3086] 2023-10-07 11:52:37,905 >>   Batch size = 1
{'loss': 0.5276, 'learning_rate': 9.59503142951776e-05, 'epoch': 0.16}












100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏| 206/207 [00:25<00:00,  8.23it/s]




































































































 20%|████████████████████████████████▎                                                                                                                                    | 499/2550 [26:25<1:30:20,  2.64s/it]
 20%|████████████████████████████████▎                                                                                                                                    | 500/2550 [26:28<1:30:21,  2.64s/it][INFO|trainer.py:3081] 2023-10-07 11:57:49,133 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-10-07 11:57:49,133 >>   Num examples = 825
[INFO|trainer.py:3086] 2023-10-07 11:57:49,133 >>   Batch size = 1












[INFO|tokenization_utils_base.py:2217] 2023-10-07 11:58:14,992 >> Special tokens file saved in sft_model_path/checkpoint-500/special_tokens_map.json
{'eval_loss': 0.5129470229148865, 'eval_runtime': 25.5414, 'eval_samples_per_second': 32.301, 'eval_steps_per_second': 8.104, 'epoch': 0.2}
10/07/2023 11:58:14 - INFO - utils.trainer - Saving model checkpoint to sft_model_path/checkpoint-500
10/07/2023 11:58:14 - INFO - utils.trainer - Trainer.model is not a `PreTrainedModel`, only saving its state dict.
[INFO|trainer.py:2894] 2023-10-07 11:58:15,505 >> Deleting older checkpoint [sft_model_path/checkpoint-1500] due to args.save_total_limit


































































































 24%|██████████████████████████████████████▊                                                                                                                              | 600/2550 [31:54<1:36:23,  2.97s/it][INFO|trainer.py:3081] 2023-10-07 12:03:14,767 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-10-07 12:03:14,767 >>   Num examples = 825
[INFO|trainer.py:3086] 2023-10-07 12:03:14,767 >>   Batch size = 1
  0%|                                                                                                                                                                                  | 0/207 [00:00<?, ?it/s]












 98%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉    | 202/207 [00:23<00:00,  8.75it/s]




































































































 27%|█████████████████████████████████████████████▎                                                                                                                       | 700/2550 [37:20<1:33:13,  3.02s/it][INFO|trainer.py:3081] 2023-10-07 12:08:41,674 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-10-07 12:08:41,674 >>   Num examples = 825
[INFO|trainer.py:3086] 2023-10-07 12:08:41,674 >>   Batch size = 1
{'loss': 0.4611, 'learning_rate': 8.532163759261085e-05, 'epoch': 0.27}












 98%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊   | 203/207 [00:24<00:00,  8.73it/s]




































































































 31%|███████████████████████████████████████████████████▊                                                                                                                 | 800/2550 [42:48<1:27:07,  2.99s/it]
 31%|███████████████████████████████████████████████████▊                                                                                                                 | 800/2550 [42:48<1:27:07,  2.99s/it][INFO|trainer.py:3081] 2023-10-07 12:14:09,098 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-10-07 12:14:09,098 >>   Num examples = 825
[INFO|trainer.py:3086] 2023-10-07 12:14:09,098 >>   Batch size = 1












 94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍          | 194/207 [00:23<00:01,  8.68it/s]



































































































 35%|██████████████████████████████████████████████████████████▏                                                                                                          | 900/2550 [48:14<1:21:47,  2.97s/it][INFO|trainer.py:3081] 2023-10-07 12:19:34,958 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-10-07 12:19:34,958 >>   Num examples = 825
[INFO|trainer.py:3086] 2023-10-07 12:19:34,958 >>   Batch size = 1
  0%|                                                                                                                                                                                  | 0/207 [00:00<?, ?it/s]















 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉        | 197/207 [00:28<00:01,  7.33it/s]



































































































 39%|████████████████████████████████████████████████████████████████▋                                                                                                    | 999/2550 [53:49<1:17:00,  2.98s/it]
 39%|████████████████████████████████████████████████████████████████▎                                                                                                   | 1000/2550 [53:52<1:16:57,  2.98s/it][INFO|trainer.py:3081] 2023-10-07 12:25:13,429 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-10-07 12:25:13,430 >>   Num examples = 825
[INFO|trainer.py:3086] 2023-10-07 12:25:13,430 >>   Batch size = 1














 98%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉    | 202/207 [00:28<00:00,  7.06it/s]
{'eval_loss': 0.44738659262657166, 'eval_runtime': 30.1028, 'eval_samples_per_second': 27.406, 'eval_steps_per_second': 6.876, 'epoch': 0.39}
10/07/2023 12:25:43 - INFO - utils.trainer - Saving model checkpoint to sft_model_path/checkpoint-1000
[INFO|tokenization_utils_base.py:2217] 2023-10-07 12:25:43,811 >> Special tokens file saved in sft_model_path/checkpoint-1000/special_tokens_map.json
[INFO|trainer.py:2894] 2023-10-07 12:25:44,329 >> Deleting older checkpoint [sft_model_path/checkpoint-500] due to args.save_total_limit


































































































 43%|██████████████████████████████████████████████████████████████████████▋                                                                                             | 1100/2550 [59:22<1:12:08,  2.98s/it][INFO|trainer.py:3081] 2023-10-07 12:30:43,374 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-10-07 12:30:43,374 >>   Num examples = 825
[INFO|trainer.py:3086] 2023-10-07 12:30:43,374 >>   Batch size = 1
{'loss': 0.4143, 'learning_rate': 6.364001947183474e-05, 'epoch': 0.43}












 94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍          | 194/207 [00:23<00:01,  8.79it/s]



































































































 47%|████████████████████████████████████████████████████████████████████████████▏                                                                                     | 1199/2550 [1:04:31<1:00:18,  2.68s/it]
 47%|████████████████████████████████████████████████████████████████████████████▏                                                                                     | 1200/2550 [1:04:34<1:00:06,  2.67s/it][INFO|trainer.py:3081] 2023-10-07 12:35:54,975 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-10-07 12:35:54,975 >>   Num examples = 825
[INFO|trainer.py:3086] 2023-10-07 12:35:54,975 >>   Batch size = 1












 92%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████             | 191/207 [00:22<00:01,  8.62it/s]



































































































 51%|███████████████████████████████████████████████████████████████████████████████████▌                                                                                | 1300/2550 [1:09:29<55:20,  2.66s/it][INFO|trainer.py:3081] 2023-10-07 12:40:49,923 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-10-07 12:40:49,923 >>   Num examples = 825
[INFO|trainer.py:3086] 2023-10-07 12:40:49,923 >>   Batch size = 1
  1%|█▋                                                                                                                                                                        | 2/207 [00:00<00:35,  5.72it/s]













 98%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊   | 203/207 [00:24<00:00,  8.61it/s]



































































































 55%|██████████████████████████████████████████████████████████████████████████████████████████                                                                          | 1400/2550 [1:14:19<50:26,  2.63s/it][INFO|trainer.py:3081] 2023-10-07 12:45:40,107 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-10-07 12:45:40,108 >>   Num examples = 825
[INFO|trainer.py:3086] 2023-10-07 12:45:40,108 >>   Batch size = 1
  3%|█████▋                                                                                                                                                                    | 7/207 [00:01<00:26,  7.41it/s]












 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████         | 196/207 [00:23<00:01,  8.73it/s]



































































































 59%|████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                   | 1499/2550 [1:19:08<46:18,  2.64s/it]
 59%|████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                   | 1500/2550 [1:19:11<46:13,  2.64s/it][INFO|trainer.py:3081] 2023-10-07 12:50:31,975 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-10-07 12:50:31,975 >>   Num examples = 825
[INFO|trainer.py:3086] 2023-10-07 12:50:31,975 >>   Batch size = 1












 97%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏    | 201/207 [00:23<00:00,  8.53it/s]
{'eval_loss': 0.4142955541610718, 'eval_runtime': 25.5559, 'eval_samples_per_second': 32.282, 'eval_steps_per_second': 8.1, 'epoch': 0.59}
10/07/2023 12:50:57 - INFO - utils.trainer - Saving model checkpoint to sft_model_path/checkpoint-1500
[INFO|tokenization_utils_base.py:2217] 2023-10-07 12:50:57,809 >> Special tokens file saved in sft_model_path/checkpoint-1500/special_tokens_map.json
[INFO|trainer.py:2894] 2023-10-07 12:50:58,325 >> Deleting older checkpoint [sft_model_path/checkpoint-1000] due to args.save_total_limit


































































































 63%|██████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                             | 1600/2550 [1:24:02<41:33,  2.63s/it][INFO|trainer.py:3081] 2023-10-07 12:55:23,180 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-10-07 12:55:23,181 >>   Num examples = 825
[INFO|trainer.py:3086] 2023-10-07 12:55:23,181 >>   Batch size = 1
{'loss': 0.363, 'learning_rate': 3.243890486737523e-05, 'epoch': 0.63}











 96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌      | 199/207 [00:23<00:00,  8.59it/s]




































































































 67%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                      | 1699/2550 [1:28:51<37:43,  2.66s/it]
 67%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                      | 1700/2550 [1:28:54<37:42,  2.66s/it][INFO|trainer.py:3081] 2023-10-07 13:00:14,970 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-10-07 13:00:14,970 >>   Num examples = 825
[INFO|trainer.py:3086] 2023-10-07 13:00:14,971 >>   Batch size = 1












100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏| 206/207 [00:24<00:00,  8.50it/s]




































































































 71%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                | 1799/2550 [1:33:43<33:40,  2.69s/it]
 71%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                | 1800/2550 [1:33:46<33:28,  2.68s/it][INFO|trainer.py:3081] 2023-10-07 13:05:07,110 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-10-07 13:05:07,110 >>   Num examples = 825
[INFO|trainer.py:3086] 2023-10-07 13:05:07,110 >>   Batch size = 1












 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉        | 197/207 [00:23<00:01,  8.63it/s]



































































































 75%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                         | 1900/2550 [1:38:37<28:45,  2.66s/it][INFO|trainer.py:3081] 2023-10-07 13:09:58,325 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-10-07 13:09:58,325 >>   Num examples = 825
[INFO|trainer.py:3086] 2023-10-07 13:09:58,325 >>   Batch size = 1
  2%|████                                                                                                                                                                      | 5/207 [00:00<00:26,  7.48it/s]












 93%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋           | 193/207 [00:23<00:01,  8.66it/s]
{'eval_loss': 0.3898219168186188, 'eval_runtime': 25.5444, 'eval_samples_per_second': 32.297, 'eval_steps_per_second': 8.104, 'epoch': 0.74}


































































































 78%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                   | 1999/2550 [1:43:26<24:22,  2.65s/it]
 78%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                   | 2000/2550 [1:43:29<24:20,  2.66s/it][INFO|trainer.py:3081] 2023-10-07 13:14:49,754 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-10-07 13:14:49,754 >>   Num examples = 825
[INFO|trainer.py:3086] 2023-10-07 13:14:49,754 >>   Batch size = 1












 96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌      | 199/207 [00:24<00:00,  8.48it/s]
{'eval_loss': 0.3822525441646576, 'eval_runtime': 25.9458, 'eval_samples_per_second': 31.797, 'eval_steps_per_second': 7.978, 'epoch': 0.78}
10/07/2023 13:15:15 - INFO - utils.trainer - Saving model checkpoint to sft_model_path/checkpoint-2000
[INFO|tokenization_utils_base.py:2217] 2023-10-07 13:15:15,991 >> Special tokens file saved in sft_model_path/checkpoint-2000/special_tokens_map.json
[INFO|trainer.py:2894] 2023-10-07 13:15:16,509 >> Deleting older checkpoint [sft_model_path/checkpoint-1500] due to args.save_total_limit


































































































 82%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                             | 2099/2550 [1:48:18<19:57,  2.66s/it]
 82%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                             | 2100/2550 [1:48:21<19:53,  2.65s/it][INFO|trainer.py:3081] 2023-10-07 13:19:41,854 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-10-07 13:19:41,854 >>   Num examples = 825
[INFO|trainer.py:3086] 2023-10-07 13:19:41,854 >>   Batch size = 1












 93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊            | 192/207 [00:22<00:01,  8.67it/s]



































































































 86%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                      | 2200/2550 [1:53:13<15:30,  2.66s/it][INFO|trainer.py:3081] 2023-10-07 13:24:33,915 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-10-07 13:24:33,915 >>   Num examples = 825
[INFO|trainer.py:3086] 2023-10-07 13:24:33,915 >>   Batch size = 1
{'loss': 0.3381, 'learning_rate': 4.971260405418576e-06, 'epoch': 0.86}












 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉        | 197/207 [00:23<00:01,  8.66it/s]



































































































 90%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                | 2300/2550 [1:58:03<11:09,  2.68s/it][INFO|trainer.py:3081] 2023-10-07 13:29:24,333 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-10-07 13:29:24,333 >>   Num examples = 825
[INFO|trainer.py:3086] 2023-10-07 13:29:24,333 >>   Batch size = 1
{'loss': 0.3571, 'learning_rate': 2.580403268771614e-06, 'epoch': 0.9}












 98%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊   | 203/207 [00:24<00:00,  8.43it/s]



































































































 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎         | 2400/2550 [2:02:53<06:35,  2.64s/it][INFO|trainer.py:3081] 2023-10-07 13:34:14,207 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-10-07 13:34:14,208 >>   Num examples = 825
[INFO|trainer.py:3086] 2023-10-07 13:34:14,208 >>   Batch size = 1
  3%|████▉                                                                                                                                                                     | 6/207 [00:00<00:26,  7.62it/s]












100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 207/207 [00:24<00:00,  6.04it/s]




































































































 98%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋   | 2499/2550 [2:07:40<02:14,  2.65s/it]
 98%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊   | 2500/2550 [2:07:43<02:12,  2.65s/it][INFO|trainer.py:3081] 2023-10-07 13:39:04,159 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-10-07 13:39:04,160 >>   Num examples = 825
[INFO|trainer.py:3086] 2023-10-07 13:39:04,160 >>   Batch size = 1











 96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌      | 199/207 [00:23<00:00,  8.46it/s]
{'eval_loss': 0.37779027223587036, 'eval_runtime': 25.4871, 'eval_samples_per_second': 32.369, 'eval_steps_per_second': 8.122, 'epoch': 0.98}
10/07/2023 13:39:29 - INFO - utils.trainer - Saving model checkpoint to sft_model_path/checkpoint-2500
[INFO|tokenization_utils_base.py:2217] 2023-10-07 13:39:30,113 >> Special tokens file saved in sft_model_path/checkpoint-2500/special_tokens_map.json
[INFO|trainer.py:2894] 2023-10-07 13:39:30,630 >> Deleting older checkpoint [sft_model_path/checkpoint-2000] due to args.save_total_limit
















































100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉| 2549/2550 [2:10:20<00:02,  2.64s/it]
{'train_runtime': 7838.2623, 'train_samples_per_second': 10.412, 'train_steps_per_second': 0.325, 'train_loss': 0.6134255076389686, 'epoch': 1.0}
10/07/2023 13:41:44 - INFO - utils.trainer - Saving model checkpoint to sft_model_path
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2550/2550 [2:10:23<00:00,  2.64s/it][INFO|trainer.py:1934] 2023-10-07 13:41:44,154 >>
Training completed. Do not forget to share your model on huggingface.co/models =)
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2550/2550 [2:10:23<00:00,  3.07s/it]
***** train metrics *****
  epoch                    =        1.0
  train_loss               =     0.6134
  train_runtime            = 2:10:38.26
  train_samples_per_second =     10.412
  train_steps_per_second   =      0.325
[INFO|tokenization_utils_base.py:2210] 2023-10-07 13:41:45,125 >> tokenizer config file saved in sft_model_path/tokenizer_config.json
[INFO|tokenization_utils_base.py:2217] 2023-10-07 13:41:45,126 >> Special tokens file saved in sft_model_path/special_tokens_map.json
[INFO|trainer.py:3081] 2023-10-07 13:41:45,196 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-10-07 13:41:45,197 >>   Num examples = 825
[INFO|trainer.py:3086] 2023-10-07 13:41:45,197 >>   Batch size = 1
 10%|█████████████████▏                                                                                                                                                       | 21/207 [00:02<00:26,  7.08it/s]
 16%|███████████████████████████▊                                                                                                                                             | 34/207 [00:04<00:24,  7.11it/s]
 24%|████████████████████████████████████████▊                                                                                                                                | 50/207 [00:06<00:21,  7.16it/s]
 31%|████████████████████████████████████████████████████▎                                                                                                                    | 64/207 [00:09<00:20,  6.97it/s]
 38%|███████████████████████████████████████████████████████████████▋                                                                                                         | 78/207 [00:11<00:18,  6.96it/s]
 43%|████████████████████████████████████████████████████████████████████████▋                                                                                                | 89/207 [00:12<00:16,  7.00it/s]
 51%|██████████████████████████████████████████████████████████████████████████████████████                                                                                  | 106/207 [00:15<00:14,  7.11it/s]
 58%|█████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                      | 120/207 [00:17<00:12,  6.84it/s]
 65%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                           | 134/207 [00:19<00:10,  6.92it/s]
 71%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                | 148/207 [00:21<00:08,  6.71it/s]
 78%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                    | 162/207 [00:23<00:06,  7.03it/s]
 86%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                        | 177/207 [00:25<00:04,  7.25it/s]
 92%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████             | 191/207 [00:27<00:02,  7.23it/s]
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏| 206/207 [00:29<00:00,  7.38it/s]
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏| 206/207 [00:29<00:00,  7.38it/s]
***** eval metrics *****
  epoch                   =        1.0
  eval_loss               =     0.3778
  eval_runtime            = 0:00:30.28
  eval_samples_per_second =     27.243
  eval_steps_per_second   =      6.836
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 207/207 [00:29<00:00,  7.02it/s]
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 207/207 [00:29<00:00,  7.02it/s]