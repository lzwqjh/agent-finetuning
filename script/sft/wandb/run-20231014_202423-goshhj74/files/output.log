

  0%|                                                                                                                             | 1/1400 [00:04<1:44:18,  4.47s/it]


































































































  7%|████████▉                                                                                                                     | 99/1400 [03:31<45:17,  2.09s/it]
  7%|████████▉                                                                                                                    | 100/1400 [03:33<45:07,  2.08s/it][INFO|trainer.py:3081] 2023-10-14 20:28:05,664 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-10-14 20:28:05,665 >>   Num examples = 46
[INFO|trainer.py:3086] 2023-10-14 20:28:05,665 >>   Batch size = 1
  0%|                                                                                                                                         | 0/12 [00:00<?, ?it/s]




































































































 14%|█████████████████▊                                                                                                           | 199/1400 [07:11<44:08,  2.21s/it]
 14%|█████████████████▊                                                                                                           | 200/1400 [07:13<43:40,  2.18s/it][INFO|trainer.py:3081] 2023-10-14 20:31:45,499 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-10-14 20:31:45,500 >>   Num examples = 46
[INFO|trainer.py:3086] 2023-10-14 20:31:45,500 >>   Batch size = 1
 67%|██████████████████████████████████████████████████████████████████████████████████████                                           | 8/12 [00:00<00:00, 10.43it/s]




































































































 21%|██████████████████████████▋                                                                                                  | 299/1400 [10:52<38:10,  2.08s/it]
 21%|██████████████████████████▊                                                                                                  | 300/1400 [10:54<38:05,  2.08s/it][INFO|trainer.py:3081] 2023-10-14 20:35:26,394 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-10-14 20:35:26,395 >>   Num examples = 46
[INFO|trainer.py:3086] 2023-10-14 20:35:26,395 >>   Batch size = 1
 25%|████████████████████████████████▎                                                                                                | 3/12 [00:00<00:00,  9.39it/s]




































































































 28%|███████████████████████████████████▋                                                                                         | 399/1400 [14:46<39:30,  2.37s/it]
 29%|███████████████████████████████████▋                                                                                         | 400/1400 [14:49<39:33,  2.37s/it][INFO|trainer.py:3081] 2023-10-14 20:39:20,852 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-10-14 20:39:20,852 >>   Num examples = 46
[INFO|trainer.py:3086] 2023-10-14 20:39:20,852 >>   Batch size = 1
 33%|███████████████████████████████████████████                                                                                      | 4/12 [00:00<00:00, 10.85it/s]




































































































 36%|████████████████████████████████████████████▌                                                                                | 499/1400 [18:45<34:25,  2.29s/it]
 36%|████████████████████████████████████████████▋                                                                                | 500/1400 [18:47<34:41,  2.31s/it][INFO|trainer.py:3081] 2023-10-14 20:43:19,448 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-10-14 20:43:19,449 >>   Num examples = 46
[INFO|trainer.py:3086] 2023-10-14 20:43:19,449 >>   Batch size = 1
 50%|████████████████████████████████████████████████████████████████▌                                                                | 6/12 [00:00<00:00, 10.21it/s]
{'eval_loss': 0.2586843967437744, 'eval_runtime': 2.1676, 'eval_samples_per_second': 21.221, 'eval_steps_per_second': 5.536, 'epoch': 3.56}
10/14/2023 20:43:21 - INFO - utils.trainer - Saving model checkpoint to sft_model_path/checkpoint-500

[INFO|tokenization_utils_base.py:2217] 2023-10-14 20:43:21,935 >> Special tokens file saved in sft_model_path/checkpoint-500/special_tokens_map.json


































































































 43%|█████████████████████████████████████████████████████▌                                                                       | 600/1400 [22:42<30:37,  2.30s/it][INFO|trainer.py:3081] 2023-10-14 20:47:14,648 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-10-14 20:47:14,648 >>   Num examples = 46
[INFO|trainer.py:3086] 2023-10-14 20:47:14,649 >>   Batch size = 1
  0%|                                                                                                                                         | 0/12 [00:00<?, ?it/s]

{'loss': 0.232, 'learning_rate': 6.425805877878794e-06, 'epoch': 4.27}



































































































 50%|██████████████████████████████████████████████████████████████▌                                                              | 700/1400 [26:13<24:00,  2.06s/it][INFO|trainer.py:3081] 2023-10-14 20:50:45,679 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-10-14 20:50:45,679 >>   Num examples = 46
[INFO|trainer.py:3086] 2023-10-14 20:50:45,680 >>   Batch size = 1
{'loss': 0.2163, 'learning_rate': 5.289013399547732e-06, 'epoch': 4.99}
 50%|██████████████████████████████████████████████████████████████▌                                                              | 700/1400 [26:15<24:00,  2.06s/it]



































































































 57%|███████████████████████████████████████████████████████████████████████▎                                                     | 799/1400 [30:05<22:41,  2.27s/it]
 57%|███████████████████████████████████████████████████████████████████████▍                                                     | 800/1400 [30:07<22:40,  2.27s/it][INFO|trainer.py:3081] 2023-10-14 20:54:39,213 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-10-14 20:54:39,214 >>   Num examples = 46
[INFO|trainer.py:3086] 2023-10-14 20:54:39,214 >>   Batch size = 1
 33%|███████████████████████████████████████████                                                                                      | 4/12 [00:00<00:00, 10.99it/s]



































































































 64%|████████████████████████████████████████████████████████████████████████████████▎                                            | 899/1400 [33:40<17:28,  2.09s/it]
 64%|████████████████████████████████████████████████████████████████████████████████▎                                            | 900/1400 [33:42<17:32,  2.11s/it][INFO|trainer.py:3081] 2023-10-14 20:58:14,730 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-10-14 20:58:14,731 >>   Num examples = 46
[INFO|trainer.py:3086] 2023-10-14 20:58:14,731 >>   Batch size = 1
 64%|████████████████████████████████████████████████████████████████████████████████▎                                            | 900/1400 [33:45<17:32,  2.11s/it]



































































































 71%|█████████████████████████████████████████████████████████████████████████████████████████▏                                   | 999/1400 [37:26<15:52,  2.37s/it]
 71%|████████████████████████████████████████████████████████████████████████████████████████▌                                   | 1000/1400 [37:28<15:49,  2.37s/it][INFO|trainer.py:3081] 2023-10-14 21:02:00,723 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-10-14 21:02:00,723 >>   Num examples = 46
[INFO|trainer.py:3086] 2023-10-14 21:02:00,723 >>   Batch size = 1
  0%|                                                                                                                                         | 0/12 [00:00<?, ?it/s]
{'eval_loss': 0.20159010589122772, 'eval_runtime': 2.0951, 'eval_samples_per_second': 21.956, 'eval_steps_per_second': 5.728, 'epoch': 7.12}
10/14/2023 21:02:02 - INFO - utils.trainer - Saving model checkpoint to sft_model_path/checkpoint-1000
[INFO|tokenization_utils_base.py:2217] 2023-10-14 21:02:03,065 >> Special tokens file saved in sft_model_path/checkpoint-1000/special_tokens_map.json
[INFO|trainer.py:2894] 2023-10-14 21:02:03,507 >> Deleting older checkpoint [sft_model_path/checkpoint-500] due to args.save_total_limit



































































































 79%|█████████████████████████████████████████████████████████████████████████████████████████████████▍                          | 1100/1400 [41:30<11:56,  2.39s/it]
 79%|█████████████████████████████████████████████████████████████████████████████████████████████████▍                          | 1100/1400 [41:30<11:56,  2.39s/it][INFO|trainer.py:3081] 2023-10-14 21:06:02,252 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-10-14 21:06:02,252 >>   Num examples = 46
[INFO|trainer.py:3086] 2023-10-14 21:06:02,252 >>   Batch size = 1
 79%|█████████████████████████████████████████████████████████████████████████████████████████████████▍                          | 1100/1400 [41:32<11:56,  2.39s/it]



































































































 86%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▎                 | 1200/1400 [45:12<06:55,  2.08s/it][INFO|trainer.py:3081] 2023-10-14 21:09:44,303 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-10-14 21:09:44,303 >>   Num examples = 46
[INFO|trainer.py:3086] 2023-10-14 21:09:44,303 >>   Batch size = 1
{'loss': 0.1458, 'learning_rate': 5.465438419957209e-07, 'epoch': 8.55}
 86%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▎                 | 1200/1400 [45:14<06:55,  2.08s/it]



































































































 93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏        | 1300/1400 [48:49<04:02,  2.42s/it][INFO|trainer.py:3081] 2023-10-14 21:13:20,829 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-10-14 21:13:20,829 >>   Num examples = 46
[INFO|trainer.py:3086] 2023-10-14 21:13:20,829 >>   Batch size = 1
{'loss': 0.136, 'learning_rate': 1.4401606792923018e-07, 'epoch': 9.26}
 93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏        | 1300/1400 [48:51<04:02,  2.42s/it]



































































































100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1400/1400 [52:42<00:00,  2.40s/it][INFO|trainer.py:3081] 2023-10-14 21:17:14,489 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-10-14 21:17:14,489 >>   Num examples = 46
[INFO|trainer.py:3086] 2023-10-14 21:17:14,489 >>   Batch size = 1
 33%|███████████████████████████████████████████                                                                                      | 4/12 [00:00<00:00, 11.33it/s]
{'loss': 0.1499, 'learning_rate': 2.1407063524436777e-10, 'epoch': 9.97}
Training completed. Do not forget to share your model on huggingface.co/models =)
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1400/1400 [52:44<00:00,  2.26s/it]
[INFO|tokenization_utils_base.py:2210] 2023-10-14 21:17:16,890 >> tokenizer config file saved in sft_model_path/tokenizer_config.json
[INFO|tokenization_utils_base.py:2217] 2023-10-14 21:17:16,890 >> Special tokens file saved in sft_model_path/special_tokens_map.json
[INFO|trainer.py:3081] 2023-10-14 21:17:16,899 >> ***** Running Evaluation *****
[INFO|trainer.py:3083] 2023-10-14 21:17:16,899 >>   Num examples = 46
[INFO|trainer.py:3086] 2023-10-14 21:17:16,899 >>   Batch size = 1
  0%|                                                                                                                                         | 0/12 [00:00<?, ?it/s]
{'eval_loss': 0.20119689404964447, 'eval_runtime': 1.9532, 'eval_samples_per_second': 23.551, 'eval_steps_per_second': 6.144, 'epoch': 9.97}
{'train_runtime': 3175.168, 'train_samples_per_second': 14.138, 'train_steps_per_second': 0.441, 'train_loss': 0.9341887222017561, 'epoch': 9.97}
10/14/2023 21:17:16 - INFO - utils.trainer - Saving model checkpoint to sft_model_path
10/14/2023 21:17:16 - INFO - utils.trainer - Trainer.model is not a `PreTrainedModel`, only saving its state dict.
***** train metrics *****
  epoch                    =       9.97
  train_loss               =     0.9342
  train_runtime            = 0:52:55.16
  train_samples_per_second =     14.138

100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:01<00:00, 10.45it/s]
***** eval metrics *****
  epoch                   =       9.97
  eval_loss               =     0.2012
  eval_runtime            = 0:00:01.94
  eval_samples_per_second =     23.684
  eval_steps_per_second   =      6.179
  perplexity              =     1.2229